"""
FastAPI ê¸°ì¤€ì˜ API ì—”ë“œí¬ì¸íŠ¸ ê³„ì¸µì…ë‹ˆë‹¤.

chat_router.py
POST /api/chat
ì„¸ì…˜ ID, ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ë“±ì„ ë°›ì•„ ëŒ€í™”í˜• ì‘ë‹µ ë°˜í™˜.
"""

import os
import re
from typing import List, Optional

from fastapi import APIRouter, HTTPException
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import Runnable
from pydantic import BaseModel

router = APIRouter(prefix="/api", tags=["chat"])


class ChatRequest(BaseModel):
    """ì±—ë´‡ ìš”ì²­ ëª¨ë¸."""

    message: str
    history: Optional[List[dict]] = []
    model_type: Optional[str] = "openai"  # "openai" ë˜ëŠ” "local"


class ChatResponse(BaseModel):
    """ì±—ë´‡ ì‘ë‹µ ëª¨ë¸."""

    response: str


def get_rag_chains():
    """ì „ì—­ RAG ì²´ì¸ê³¼ í• ë‹¹ëŸ‰ ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.

    ì´ í•¨ìˆ˜ëŠ” api_server.pyì˜ ì „ì—­ ë³€ìˆ˜ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´
    api_server ëª¨ë“ˆì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•©ë‹ˆë‹¤.
    """
    # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import
    import sys

    # api_server ëª¨ë“ˆì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if "app.api_server" in sys.modules:
        from .. import api_server
    else:
        # ëª¨ë“ˆì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ì§ì ‘ import
        import importlib

        api_server = importlib.import_module("app.api_server")

    return {
        "openai_rag_chain": api_server.openai_rag_chain,
        "local_rag_chain": api_server.local_rag_chain,
        "openai_quota_exceeded": api_server.openai_quota_exceeded,
        "openai_llm": api_server.openai_llm,
        "openai_embeddings": api_server.openai_embeddings,
    }


@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±—ë´‡ API ì—”ë“œí¬ì¸íŠ¸ - LangChain RAG ì²´ì¸ ì‚¬ìš©."""
    # ì „ì—­ RAG ì²´ì¸ ê°€ì ¸ì˜¤ê¸°
    chains = get_rag_chains()
    openai_rag_chain: Optional[Runnable] = chains["openai_rag_chain"]
    local_rag_chain: Optional[Runnable] = chains["local_rag_chain"]
    openai_quota_exceeded: bool = chains["openai_quota_exceeded"]
    openai_llm = chains["openai_llm"]
    openai_embeddings = chains["openai_embeddings"]

    # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ RAG ì²´ì¸ ì„ íƒ
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ model_typeì´ ì—†ìœ¼ë©´ .envì˜ LLM_PROVIDER ì‚¬ìš©
    model_type = request.model_type or os.getenv("LLM_PROVIDER", "openai")
    if model_type:
        model_type = model_type.lower()

    # ë””ë²„ê¹…: ë°›ì€ model_type ë¡œê·¸ ì¶œë ¥
    print(
        f"[DEBUG] ë°›ì€ model_type: {request.model_type}, ì²˜ë¦¬ëœ model_type: {model_type}"
    )

    # "midm"ë„ "local"ë¡œ ì²˜ë¦¬
    if model_type == "midm":
        model_type = "local"

    if model_type == "openai":
        if not openai_rag_chain:
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì—¬ë¶€ í™•ì¸
            if openai_quota_exceeded:
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ì¸ ê²½ìš° ëª…í™•í•œ ë©”ì‹œì§€
                error_msg = (
                    "âš ï¸ OpenAI API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                    "ì„œë²„ ì‹œì‘ ì‹œ '[WARNING] OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼' ë©”ì‹œì§€ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                    "í•´ê²° ë°©ë²•:\n"
                    "1. OpenAI ê³„ì •ì˜ ì‚¬ìš©ëŸ‰ ë° í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”\n"
                    "2. OpenAI ê³„ì •ì— ê²°ì œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ í• ë‹¹ëŸ‰ì„ ëŠ˜ë¦¬ì„¸ìš”\n"
                    "3. ë˜ëŠ” 'ğŸ–¥ï¸ ë¡œì»¬ ëª¨ë¸' ë²„íŠ¼ì„ ì„ íƒí•˜ì—¬ ë¡œì»¬ Midm ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”"
                )
            elif not openai_llm and not openai_embeddings:
                # ë‘˜ ë‹¤ ì´ˆê¸°í™” ì‹¤íŒ¨ (í• ë‹¹ëŸ‰ ì´ˆê³¼ê°€ ì•„ë‹Œ ê²½ìš°)
                error_msg = (
                    "OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                    "ê°€ëŠ¥í•œ ì›ì¸:\n"
                    "1. OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤\n"
                    "2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ\n\n"
                    "í•´ê²° ë°©ë²•:\n"
                    "- .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”\n"
                    "- ë˜ëŠ” 'ë¡œì»¬ ëª¨ë¸' ë²„íŠ¼ì„ ì„ íƒí•˜ì—¬ ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”"
                )
            else:
                # ì¼ë¶€ë§Œ ì‹¤íŒ¨
                error_details = []
                if not openai_llm:
                    error_details.append("OpenAI LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                if not openai_embeddings:
                    error_details.append("OpenAI Embeddingsê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                error_msg = f"OpenAI RAG ì²´ì¸ ìƒì„± ì‹¤íŒ¨: {', '.join(error_details)}"

            print(f"[ERROR] OpenAI ëª¨ë¸ ì‚¬ìš© ì‹œë„ ì‹¤íŒ¨: {error_msg}")
            raise HTTPException(
                status_code=503,
                detail=error_msg,
            )
        current_rag_chain = openai_rag_chain
    elif model_type == "local" or model_type == "midm":
        if not local_rag_chain:
            raise HTTPException(
                status_code=503,
                detail="ë¡œì»¬ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Midm ëª¨ë¸ê³¼ sentence-transformersë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            )
        print(f"[DEBUG] ë¡œì»¬ RAG ì²´ì¸ ì‚¬ìš© (model_type: {model_type})")
        current_rag_chain = local_rag_chain
    else:
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì…ë‹ˆë‹¤: {model_type}. 'openai' ë˜ëŠ” 'local'ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
        )

    try:
        # ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        chat_history = []
        if request.history:
            for msg in request.history:
                if msg.get("role") == "user":
                    chat_history.append(HumanMessage(content=msg.get("content", "")))
                elif msg.get("role") == "assistant":
                    chat_history.append(AIMessage(content=msg.get("content", "")))

        # RAG ì²´ì¸ ì‹¤í–‰
        result = current_rag_chain.invoke(
            {
                "input": request.message,
                "chat_history": chat_history,
            }
        )

        # ì²´ì¸ ê²°ê³¼ì—ì„œ ë‹µë³€ ì¶”ì¶œ
        response_text = result.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # response_textê°€ Noneì´ê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if response_text is None:
            response_text = "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            response_text = str(response_text)

        # ì‘ë‹µì—ì„œ ì´ì „ ëŒ€í™” ë‚´ìš© ì œê±° (ì¤‘ë³µ ë°©ì§€)
        # Midm ëª¨ë¸ì—ì„œ ì´ë¯¸ ì •ë¦¬í–ˆìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ ì²´í¬ë§Œ ìˆ˜í–‰
        if response_text and (
            "Human:" in response_text or "Assistant:" in response_text
        ):
            # ë¹ ë¥¸ ì •ê·œì‹ìœ¼ë¡œ ë§ˆì§€ë§‰ Assistant: ì´í›„ë§Œ ì¶”ì¶œ
            assistant_match = re.search(
                r"Assistant:\s*(.+?)(?:\nHuman:|$)", response_text, re.DOTALL
            )
            if assistant_match:
                response_text = assistant_match.group(1).strip()

        # ë¹ˆ ì‘ë‹µ ë°©ì§€
        if not response_text or not response_text.strip():
            response_text = "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return ChatResponse(response=response_text)

    except Exception as e:
        error_msg = str(e)
        print(f"[ERROR] ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {error_msg}")

        # OpenAI API í˜¸ì¶œëŸ‰ ì´ˆê³¼ ì—ëŸ¬ í™•ì¸
        if (
            "quota" in error_msg.lower()
            or "429" in error_msg
            or "insufficient_quota" in error_msg
            or "exceeded" in error_msg.lower()
        ):
            error_detail = "OpenAI API í˜¸ì¶œëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            raise HTTPException(
                status_code=429,
                detail=error_detail,
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg[:200]}",
            )
