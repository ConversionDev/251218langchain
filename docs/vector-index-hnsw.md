# pgvector 벡터 인덱스: HNSW 전략

베이스 테이블(disclosures, players, teams, schedules, stadiums)의 모든 데이터를 임베딩(Vector)으로 구성하고 **HNSW(Hierarchical Navigable Small World)** 인덱스를 사용하는 방식은 AI 기반 검색(RAG 등)에서 선호되는 전략입니다.  
CRUD 지연·자원 소모라는 단점을 극복하는 배경과, IVFFlat 대비 HNSW의 장점을 정리합니다.

---

## 1. HNSW의 핵심: 다층 그래프 구조

HNSW는 데이터를 단순 나열이 아니라 **여러 층으로 구성된 계층형 그래프**로 만듭니다.

- **구조**: 상위 층일수록 노드 수가 적고 노드 간 거리가 멀어 고속 이동에 적합하고, 하위 층일수록 데이터가 밀집해 세밀한 탐색이 가능합니다.
- **작동**: 쿼리가 들어오면 가장 상위 층에서 성긴 탐색을 시작해 목표 근처로 빠르게 이동한 뒤, 아래 층으로 내려가며 유사 데이터를 정교하게 찾습니다.
- **효과**: 전수 조사(Flat Search) 없이 **로그 시간 복잡도 O(log N)**에 수렴하는 검색 속도를 보장합니다.

---

## 2. CRUD 지연 및 자원 단점 극복 배경

"베이스 테이블을 전부 임베딩 테이블로 구성할 때 CRUD가 느리다"는 말은 주로 **인덱스 갱신(C, U, D)** 과정에서 나옵니다.

- **느린 구축·업데이트**: 새 행이 들어올 때마다 적절한 층에 노드를 배치하고 이웃 노드와의 연결(Edge)을 계산해야 하므로, IVFFlat(클러스터링)보다 연산량이 많습니다.
- **메모리**: 그래프 연결 정보를 메모리에 두어야 하므로 원본 벡터보다 많은 RAM이 필요합니다.

**극복 포인트**:

- **증분 업데이트**: HNSW는 IVFFlat과 달리 **사전 학습(Training) 단계가 없습니다**.  
  따라서 데이터가 실시간으로 들어올 때 인덱스를 즉시 갱신할 수 있어, 구축 비용은 크지만 **실시간성** 측면에서는 유리합니다.
- **빈 테이블에도 인덱스 생성 가능**: IVFFlat은 전체 데이터로 centroid를 학습해야 하므로 데이터가 쌓인 뒤에만 인덱스를 만들 수 있습니다.  
  HNSW는 **테이블에 데이터가 없어도** 인덱스를 미리 정의해 두고, 데이터가 들어올 때마다 노드를 추가하는 방식으로 운영할 수 있습니다.
- 하드웨어·압축: PQ(Product Quantization) 결합, NVMe SSD 활용 등으로 메모리·I/O 부담을 줄이는 방식도 사용됩니다.

---

## 3. IVFFlat vs HNSW 비교

| 구분           | IVFFlat              | HNSW                    |
|----------------|----------------------|-------------------------|
| 인덱스 구조    | 클러스터링(군집화)   | 계층형 그래프           |
| 사전 학습      | 필요 (데이터 필요)   | 불필요 (빈 테이블 가능) |
| 검색 속도      | 빠름 (분포 영향 있음)| 매우 빠름 (안정적)      |
| 메모리 효율    | 우수                 | 낮음 (RAM 다소 필요)    |
| 정확도(Recall) | 보통                 | 매우 높음               |

---

## 4. "학습 단계가 없다"는 것의 의미

- **IVFFlat**: 전체 데이터로 그룹(Centroids)을 나누는 Training이 필수입니다. 데이터가 적을 때 인덱스를 만들면, 나중에 데이터가 늘어났을 때 검색 품질이 급격히 나빠질 수 있습니다.
- **HNSW**: 데이터가 없을 때도 인덱스를 정의해 두고, 데이터가 들어올 때마다 그래프에 노드를 하나씩 추가하는 방식입니다.  
  **데이터가 수시로 추가/삭제되는 환경**에서 운영 효율이 높습니다.

---

## 5. 본 프로젝트와의 연관

- **임베딩**: BGE-m3, 벡터 차원 1024 (`vector(1024)`).
- **테이블**: `disclosures`, Soccer 베이스 테이블에 `embedding_content` + `embedding` 컬럼으로 단일 테이블 패턴 사용.
- **검색**: RAG에서 유사도 검색 시 pgvector의 거리 연산자(`<->` 등)를 사용.  
  HNSW 인덱스를 `embedding` 컬럼에 걸면 쿼리 성능·재현율을 동시에 확보할 수 있습니다.

인덱스 생성 예시(BGE-m3·코사인 거리 기준):

```sql
-- 예: disclosures
CREATE INDEX ON disclosures
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 검색 시 정확도 우선이면
SET hnsw.ef_search = 100;
```

- **m**, **ef_construction**, **ef_search**는 데이터 규모·정확도 요구에 맞게 조정합니다(문서 규모가 크고 전문성이 높으면 m·ef_construction을 높이고, 보고서 품질을 위해 ef_search를 높게 두는 식).

**본 프로젝트 적용**: Alembic 마이그레이션 `004_hnsw_indexes.py`에서 `disclosures`, `stadiums`, `teams`, `players`, `schedules`의 `embedding` 컬럼에 HNSW 인덱스를 생성합니다.  
- 파라미터: `m=24`, `ef_construction=128` (복잡한 문서·높은 recall).  
- 적용: `alembic upgrade head` 실행.  
- 검색 정확도 우선 시: RAG/검색 쿼리 전에 `SET hnsw.ef_search = 100` (세션 또는 연결 초기화 시 설정 가능).

---

## 6. 적용 전략 요약

- **언제 적용할지**: 데이터 적재·정제가 어느 정도 안정된 뒤, **쿼리 지연이나 recall 부족**이 관찰될 때 HNSW 도입을 검토하는 것이 좋습니다.
- **순서**: 테이블 생성 → 데이터 적재 → 그 다음 `CREATE INDEX ... USING hnsw` 실행.  
  데이터가 있는 상태에서 인덱스를 만들면 pgvector가 구조를 더 잘 최적화합니다.
- **트레이드오프**: 구축 시간·메모리는 더 쓰고, 검색 속도·정확도·실시간 증분 업데이트를 얻는 선택입니다.  
  HR 전략 제언·공시 분석처럼 **검색 정확도와 응답 속도**가 중요한 RAG에는 적용하는 것이 유리합니다.
