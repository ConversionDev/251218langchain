{
  "best_global_step": 500,
  "best_metric": 0.5811273455619812,
  "best_model_checkpoint": "C:\\Users\\kku10\\OneDrive\\\ubb38\uc11c\\RAG\\app\\artifacts\\fine_tuned\\exaone\\adapters\\checkpoint-500",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 608,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08223684210526316,
      "grad_norm": 2.5646913051605225,
      "learning_rate": 9.6e-05,
      "loss": 2.8345,
      "step": 25
    },
    {
      "epoch": 0.16447368421052633,
      "grad_norm": 1.4323874711990356,
      "learning_rate": 0.000196,
      "loss": 1.2671,
      "step": 50
    },
    {
      "epoch": 0.24671052631578946,
      "grad_norm": 1.3577431440353394,
      "learning_rate": 0.00019908848681582391,
      "loss": 0.9495,
      "step": 75
    },
    {
      "epoch": 0.32894736842105265,
      "grad_norm": 1.07125723361969,
      "learning_rate": 0.00019621873281596092,
      "loss": 0.792,
      "step": 100
    },
    {
      "epoch": 0.41118421052631576,
      "grad_norm": 1.0127053260803223,
      "learning_rate": 0.0001914459126539224,
      "loss": 0.7103,
      "step": 125
    },
    {
      "epoch": 0.4934210526315789,
      "grad_norm": 0.9736283421516418,
      "learning_rate": 0.00018486442574947511,
      "loss": 0.7011,
      "step": 150
    },
    {
      "epoch": 0.5756578947368421,
      "grad_norm": 1.0210946798324585,
      "learning_rate": 0.0001766044443118978,
      "loss": 0.6871,
      "step": 175
    },
    {
      "epoch": 0.6578947368421053,
      "grad_norm": 0.8877589702606201,
      "learning_rate": 0.0001668293387235891,
      "loss": 0.6905,
      "step": 200
    },
    {
      "epoch": 0.7401315789473685,
      "grad_norm": 0.9892840385437012,
      "learning_rate": 0.00015573244631224365,
      "loss": 0.6507,
      "step": 225
    },
    {
      "epoch": 0.8223684210526315,
      "grad_norm": 1.0563380718231201,
      "learning_rate": 0.000143533247420569,
      "loss": 0.6701,
      "step": 250
    },
    {
      "epoch": 0.9046052631578947,
      "grad_norm": 0.9269952774047852,
      "learning_rate": 0.00013047302440530537,
      "loss": 0.6331,
      "step": 275
    },
    {
      "epoch": 0.9868421052631579,
      "grad_norm": 1.0200198888778687,
      "learning_rate": 0.00011681008942421483,
      "loss": 0.6441,
      "step": 300
    },
    {
      "epoch": 1.069078947368421,
      "grad_norm": 1.1700947284698486,
      "learning_rate": 0.00010281467539845051,
      "loss": 0.5921,
      "step": 325
    },
    {
      "epoch": 1.1513157894736843,
      "grad_norm": 1.0692073106765747,
      "learning_rate": 8.87635911996177e-05,
      "loss": 0.6087,
      "step": 350
    },
    {
      "epoch": 1.2335526315789473,
      "grad_norm": 1.1279572248458862,
      "learning_rate": 7.493474677412794e-05,
      "loss": 0.6009,
      "step": 375
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 1.216982364654541,
      "learning_rate": 6.160165648990048e-05,
      "loss": 0.5569,
      "step": 400
    },
    {
      "epoch": 1.3980263157894737,
      "grad_norm": 1.0620238780975342,
      "learning_rate": 4.902802942119293e-05,
      "loss": 0.5732,
      "step": 425
    },
    {
      "epoch": 1.4802631578947367,
      "grad_norm": 0.8901683688163757,
      "learning_rate": 3.746255356783632e-05,
      "loss": 0.5838,
      "step": 450
    },
    {
      "epoch": 1.5625,
      "grad_norm": 1.3299388885498047,
      "learning_rate": 2.713397716940763e-05,
      "loss": 0.5611,
      "step": 475
    },
    {
      "epoch": 1.6447368421052633,
      "grad_norm": 1.1966068744659424,
      "learning_rate": 1.8246584398770493e-05,
      "loss": 0.5615,
      "step": 500
    },
    {
      "epoch": 1.6447368421052633,
      "eval_loss": 0.5811273455619812,
      "eval_runtime": 23.1957,
      "eval_samples_per_second": 11.683,
      "eval_steps_per_second": 2.932,
      "step": 500
    },
    {
      "epoch": 1.7269736842105263,
      "grad_norm": 1.2008130550384521,
      "learning_rate": 1.097615491916485e-05,
      "loss": 0.5411,
      "step": 525
    },
    {
      "epoch": 1.8092105263157894,
      "grad_norm": 1.3032338619232178,
      "learning_rate": 5.466487218911942e-06,
      "loss": 0.5729,
      "step": 550
    },
    {
      "epoch": 1.8914473684210527,
      "grad_norm": 1.280290961265564,
      "learning_rate": 1.8265544871020723e-06,
      "loss": 0.5557,
      "step": 575
    },
    {
      "epoch": 1.973684210526316,
      "grad_norm": 1.2550665140151978,
      "learning_rate": 1.2834928289472416e-07,
      "loss": 0.5283,
      "step": 600
    }
  ],
  "logging_steps": 25,
  "max_steps": 608,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.79079488847872e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
